

\renewcommand{\thefigure}{S\arabic{figure}}

\setcounter{figure}{0}

\renewcommand{\thetable}{S\arabic{table}}

\setcounter{table}{0}


## Population Model {.unnumbered}


The core of our model is a Pella-Tomlinson [@pella1969] production model in the manner of [@winker2018]. While models of these kinds abstract away many important details of fish biology and fleet behavior, they are the highest resolution model that the potential data evaluated here will support.

```{r param-tab}
cd <- data_frame(Parameter = "Carrying Capacity", Abbreviation = "$K$", `Default Prior` = "Prior predictive tuning") %>%
  rbind(c("Growth rate", "$r$", "Thorson, 2020 [@thorson2020] updated by prior predictive tuning")) %>%
  rbind(c("Shape parameter", "$m$", "Drawn from Thorson et al. 2012 (@thorson2012)")) %>%
  rbind(c("Catchability", "$q$", "$LN(1e^{-3}, 1)$")) %>%
  rbind(c("Observation Error", "$\\sigma_{obs}$", "$LN(.05,1)$")) %>%
  rbind(c("Ratio of process to observation error", "$\\gamma$", "$LN(.5,0.25)$")) %>%
  rbind(c("Initial State", "$B_0$", "Posterior probability dist. of catch-based regressions"))

 
knitr::kable(
  cd,
  align = "l",
  escape = F,
  row.names = F,
  caption = "Name, abbreviations, and priors distribution for parameters potentially estimated by sraplus in this manuscript. LN refers to log normal, where the mean is reported on the unit scale.",
  format = "pipe"
) %>%
  kableExtra::kable_styling(full_width = T, font_size = 9) %>%
  kableExtra::row_spec(0, bold = T)
```

\newpage

```{r shape-tab}

knitr::kable(
  sraplus::ssb0msy_to_ssb0 %>% rename(
    "Taxanomic Group" = tax_group,
    "SSBMSY/SSB0" = ssbmsy_to_ssb0,
    "SSBMSY/SSB0 SD" = ssbmsy_to_ssb0_sd
  ),
    align = "l",
  escape = F,
  row.names = F,
  format = "pipe",
  caption = "SSBMSY to SSB ratios from Thorson et al. (2012) used in the paper. Taxa not within the groups assigned at the genus level by Thorson et al. (2012) are assigned the ratio reported for 'Other'"
)

```




## Prior Predictive Tuning {.unnumbered}

Our prior predictive tuning regime is similar in spirit to Bayesian melding [@poole2000]. Our solution amounts to a two-step sample-importance-resampling (SIR) algorithm. We first run the standard SIR algorithm as described above. We then break the resulting draws into bins based on terminal stock status, and calculate the mean sampling probability of each bin. The net result of this is that it allows users to place explicit prior on stock status, and then adjust their priors on life history parameters to reflect this prior, rather than creating a complicated and biased prior on stock status based on a mixture of explicit and implicit priors.

The SRA algorithm works in two steps. First, the algorithm rejects any draws that resulted in the collapse of the population (biomass less than catch in a given timestep). From there a standard SRA would sample from the priors in proportion to the stated prior on recent stock status. If the bulk of the prior on terminal stock status was concentrated at 50% of *K*, combinations of *r* and *K* that produce terminal stock status near 50% of *K* are sampled proportionally more frequently. However, lower values of terminal stock status have fewer candidate values of *r* and *K*, since it becomes harder and harder to find viable pairs that come close to but do not crash the population at any time step. Conversely, in the absence of constraints higher values of stock status have infinite combinations of plausible *r* and *K* combinations: since under this model the population cannot be greater than carrying capacity, as for example *K* approaches infinity terminal stock status asymptotes at close to 100% of *K*. The net result of this is that even though individual combinations of *r* and *K* that produce higher stock status than the mean of the prior on recent stock status individually have lower probability of being sampled, there are many more opportunities for the lower-probability events that produce higher stock status to be sampled. As a result, the post-model-pre-data prior on terminal depletion will always be higher under this method than the supplied prior on stock status.

The net result of our correction is a post-model-pre-data distribution of life history parameters that produce a distribution of recent stock status that roughly matches the supplied prior on recent stock status. In effect, this process answers the question "given the model, what combinations of parameters produce my prior on recent stock status". This is only an approximate solution, but it helps ensure that the post-model-pre-data distribution of stock status much more closely matches the stated prior on recent stock status, and reduced the positive bias resulting from use of the raw SRA algorithm (Fig.\@ref(fig:bias-plot), Fig.\@ref(fig:ppplot)).

```{r bias-plot, fig.cap = "Post-model-pre-data distribution of depletion (biomass relative to carrying capacity) from raw SRA algorithm (untuned, top row), from SRA algorithm with approximate tuning applied (tuned, middle row), compared to the supplised prior on depletion (bottom row). Black vertical line indicates median value. "}

id = unique(ram_comp_data$stockid)

ex <- ram_data %>% 
  filter(stockid %in% id[[1]]) 

# fit using catch heuristic

co_driors <- sraplus::format_driors(taxa = unique(ex$scientificname),
                                 catch = ex$catch, 
                                 years = ex$year,
                                 terminal_state = 0.25,
                                 terminal_state_cv = 0.5,
                                 b_ref_type = "k")

biased_co_fit <- sraplus::fit_sraplus(driors = co_driors, tune_prior_predictive = FALSE,
                                      estimate_shape = FALSE, estimate_proc_error = TRUE)

biased_depletion <- biased_co_fit$fit %>% 
  filter(variable == "dep_t") %>%
  filter(year == max(year)) %>% 
  mutate(set = "Untuned Post-Model-Pre-Data") %>% 
  select(year, value, set)


co_fit <- sraplus::fit_sraplus(driors = co_driors, tune_prior_predictive = TRUE,
                                      estimate_shape = FALSE, 
                               estimate_proc_error = TRUE)

tuned_depletion <- co_fit$fit %>% 
  filter(year == max(year), variable == "dep_t") %>% 
  mutate(set = "Tuned Post-Model-Pre-Data") %>% 
  select(year, value, set)

prior <- tuned_depletion %>% 
  mutate(value = rlnorm(n(), log(0.25), 0.5)) %>% 
    mutate(set = "Prior")

comps <- biased_depletion %>% 
  bind_rows(tuned_depletion) %>% 
  bind_rows(prior) %>% 
  group_by(set) %>% 
  mutate(valrank = percent_rank(value)) %>% 
  filter(between(valrank, .05, .95))

comps %>% 
  ggplot(aes(x = value, y = set)) + 
  ggridges::geom_density_ridges(alpha = 0.9,
                                quantile_lines = TRUE, quantiles = 2) +
  scale_x_continuous(limits = c(0, 1.2), name = "Depletion (B/K)") + 
  scale_y_discrete(name = '')


```



```{r ppplot, fig.cap="Prior posterior plots of fits for case study fishery"}

a = get_prior_posterior(co_fit, co_driors)

a$prior_posterior %>% 
  ggplot(aes(x = variable, y = mean, ymin = lower, ymax = upper, color = source)) + 
  geom_pointrange(position = position_dodge(width = 0.1)) + 
  facet_wrap(~variable, scales = "free") + 
  theme(axis.text.x = element_blank()) + 
  scale_color_discrete(name = '') + 
  scale_y_continuous(name = "Value") + 
  scale_x_discrete(name = '') + 
  theme_minimal()


```




## Prior Generating Regressions {.unnumbered}


### Catch-Only Priors {.unnumbered}

Many of the current methods for estimating global stock status of unassessed stocks are based on predicting stock status from characteristics of the catch history [@costello2012b; @costello2016a; @pauly2007; @rosenberg2018]. While these catch-only methods have been shown to have serious shortcomings [@free2020], we include them as a point of reference given their ubiquity in the global assessment literature.

We used data from the RAM Legacy Stock Assessment Database to estimate a regression of stock status as a function of catch history characteristics. To facilitate the process, we first fit a spectral clustering algorithm to the scaled catch histories of fisheries in RAM, in order identify four possible clusters of catch history types within the the data. Emergent clusters show for example one built around a downward "one way trip" style catch histories, others with a boom and bust pattern, others with stable but fluctuating catches.

We then trained a classification algorithm to predict which catch cluster a given fishery would fall into based on the shape of its catch history. This algorithm was then used to assign fisheries to one of the four identified catch history types, and the catch history type was then used as a hierarchical term within our catch-based regressions (where *s* refers to a smoothing term). For the first regression, we restrict the data to the first year of data available for each fishery *i*, in order to estimate initial stock status

$$log(value_i) \sim normal(s(\frac{first(catch)}{max(catch)} | cluster_i) + s(log(lengthi)|cluster_i) + 1, \sigma)$$

For the second regression, we included data for all available years *y* for fishery *i*. The model is then used to construct a prior on fishery status in the terminal year of the data

$$log(value_{i,y}) \sim normal(s(fyear | cluster_i) + s(\frac{catch_{i,y}}{max(catch_i)} | cluster_i) + cluster_i, \sigma)$$

where *fyear* is the year of the fishery, starting from 0.

Fits for the catch-only prior-generating regression are visible in Fig.\@ref(fig:catch-reg).


```{r catch-reg,fig.cap = "Observed (x-axis) vs posterior predictive (y-axis) B/B~MSY~ for regression of catch on B/B~MSY~"}

fit <- sraplus::catch_b_model

fit_data <- fit$data %>% 
  group_by(stockid) %>% 
  filter(year == max(year))

pp <- posterior_predict(fit, draws = 1000, newdata = fit_data)

r2_plot <- tibble(r2 = bayes_R2(fit)) %>% 
  ggplot(aes(r2)) + 
  geom_histogram() + 
  labs(subtitle = "B) Bayesian R2")

pi_plot <- ppc_scatter_avg(y = fit_data$log_value, yrep = pp) + 
  coord_flip() +
  scale_y_continuous(name = "Observed Log B/Bmsy") + 
  scale_x_continuous(name = "Posterior Predictive B/Bmsy") +
  labs(subtitle = "A) Observed vs. Posterior Predictive") +
 pub_theme


pi_plot + r2_plot
```


### Fisheries Management Index Priors {.unnumbered}


The Fisheries Management Index (FMI), as presented in [@melnychuk2017], utilizes surveys filled out by regional experts to score a fishery against a set of 46 specific questions for individual species about what elements of fisheries management were in place. These questions are then aggregated into broader categories of science, enforcement, management, and socioeconomic. The higher the score, the better the expert judges that a given metric is met in that fishery. Importantly, FMI surveys can be filled out in the absence of stock assessments. This allows us to explore how FMI values map onto stock status, and explore the ability then to use FMI scores to produce priors on stock status for unassessed fisheries (in a manner similar to [@osio2015] and [@cope2015]).

The final selected model relating FMI variable to stock status metrics was a generalized additive model (GAM) of the form

$$log(value_i) \sim N(s(research_i) + s(management_i) +
s(enforcement_i) + s(socioeconomics_i) + \frac{catch_i}{max(catch)_i)} + 1,\sigma_{SAR})$$

Fits for the FMI prior-generating regression are visible in Fig.\@ref(fig:fmi-fit).

```{r fmi-fit, fig.cap = "Observed (x-axis) vs posterior predictive (y-axis) F/F~MSY~ for regression of fisheries management index (FMI) on F/F~MSY~"}

fit <- sraplus::fmi_models$fit[sraplus::fmi_models$metric == "mean_uumsy"][[1]]

fit_data <- fit$data

pp <- posterior_predict(fit, draws = 1000)

r2_plot <- tibble(r2 = bayes_R2(fit)) %>% 
  ggplot(aes(r2)) + 
  geom_histogram() + 
  labs(subtitle = "B) Bayesian R2")

pi_plot <- ppc_intervals(y = fit_data$log_value, yrep = pp, x = fit_data$log_value) + 
  scale_x_continuous(name = "Observed Log F/Fmsy") + 
  scale_y_continuous(name = "Posterior Predictive F/Fmsy") +
  labs(subtitle = "A) Observed vs. Posterior Predictive") +
 pub_theme

pi_plot + r2_plot
```

### Swept Area Ratio Priors {.unnumbered}


[@amoroso2018] provides an extensive database of trawling footprints throughout the world, including both regions heavily covered by stock assessments and largely unassessed areas. This makes the trawl footprint data an ideal candidate for supporting global stock assessment efforts. As illustrated in [@amoroso2018], there is an evident positive relationship between the swept area ratio (SAR,the total annual area trawled divided by the total area of the region) and U/U~MSY~. Note that SAR can be greater than 1 since the same area can be trawled multiple times in a year, e.g. if all trawl-able areas are trawled twice a year then the SAR will be 2. Also note the skewed distribution of SAR values with most concentrated well below 1 and only a handful above 1.

The final selected model relating SAR to to stock status metrics was

$$log(value_i) \sim normal(s(SAR_i) + s(\frac{catch_i}{max(catch)_i)}) + 1,\sigma_{SAR}) $$
Fits for the SAR prior-generating regression are visible in Fig.\@ref(fig:sar-fit).

```{r sar-fit, fig.cap = "Observed (x-axis) vs posterior predictive (y-axis) F/F~MSY~ for regression of swept area ratio (SAR) on F/F~MSY~"}
fit <- sraplus::sar_models$fit[sraplus::sar_models$metric == "mean_uumsy"][[1]]

fit_data <- fit$data

pp <- posterior_predict(fit, draws = 1000)

r2_plot <- tibble(r2 = bayes_R2(fit)) %>% 
  ggplot(aes(r2)) + 
  geom_histogram() + 
  labs(subtitle = "B) Bayesian R2")

pi_plot <- ppc_intervals(y = fit_data$log_value, yrep = pp, x = fit_data$log_value) + 
  scale_x_continuous(name = "Observed Log F/Fmsy") + 
  scale_y_continuous(name = "Posterior Predictive F/Fmsy") +
  labs(subtitle = "A) Observed vs. Posterior Predictive") +
 pub_theme

pi_plot + r2_plot

```


## Value of Information Calculation {.unnumbered}


We performed a value-of-information (VOI) exercise we assessed performance as the root-mean-squared-error of B/B~MSY~ over the most recent 5 years of the fishery, in order to evaluate the ability of the model to capture the recent trends in stock status and not just the most recent year. We evaluate the contributing of each data type to RMSE using a Gamma GLM with a log link of the form

$$rmse \sim  Gamma(\pmb{\beta}{\pmb{X}} + (1 | stock), shape, scale)$$

Where $\pmb{\beta}$ is the vector of coefficients associated with the matrix of dummy variables marking the use of different data types in the vector $\pmb{X}$

## F/F~MSY~ Performance {.unnumbered}

Our results focused on the performance of candidate models in estimating B/B~MSY~, as this reflects the broad mission of the FAO's SOFIA reports to assess the current biomass status of global fisheries. However, fishing mortality rates, specifically F/F~MSY~ are also of importance to managers and commonly considered as an output of catch-only models. 

As such, we repeated our performance calculations summarized in Figures \@ref(fig: mpe-map)-\@ref(fig:acc-map) but now focused on F/F~MSY~. Performance was comparably poor to the B/B~MSY~ based results, with the exception that the default settings of CMSY produced a consistent positive bias in F/F~MSY~. 

```{r uperf-tab}

knitr::kable(uperf %>% rename(MPE = mpe, MAPE = mape, Accuracy = accuracy), digits = 2,
             caption = "Global performance statistics in the most recent year available of models using different sources of data. MPE = median percent error (bias), MAPE = median absolute percent error (error), Accuracy = percent of times that stocks were classified to the correct FAO status bin (underfished, maximally sustainably fished, overfished). Performance is judged relative to *F/F~MSY~* values reported values in RAM Legacy Stock Assessment Database.",
              format = "pipe")

```

```{r umpe-map, fig.width=8, fig.height=6, fig.cap="Median percent error (MPE, predicted relative to observed) in most recent *F/F~MSY~* by FAO statistical area from different data sources. RLSADB Index refers to catch and abundance index drawn from RLSADB. Effective CPUE refers to an index of abundance based on reconstructed effort data. Effective CPUE+ uses CPUE along with Fisheries Management Index (FMI) and/or swept area ratio (SAR) data. For both CPUE series 'nominal' assumes a 0% technology creep, for 'effective' a 2.6% technology creep is assumed. FMI uses FMI scores to develop a prior on recent fishing mortality rates, SAR does the same but based on swept area ratio. CMSY uses the methods from Froese et al. 2017 [@froese2017]. Guess assigns a random recent *F/F~MSY~* of 0.4,1, or 1.6. Panels ordered in ascending (starting from top left) mean MPE at the FAO region level. "}
ramu_mpe_map_plot

ggsave(here("documents","figs","u-mpe-map.pdf"), ram_mpe_map_plot, width = 8, height = 6)
```

```{r umape-map, fig.cap = "Median absolute percent error (MAPE) in most recent *F/F~MSY~* by FAO statistical area from different data sources. RLSADB Index refers to catch and abundance index drawn from RLSADB. Effective CPUE refers to an index of abundance based on reconstructed effort data. Effective CPUE+ uses CPUE along with Fisheries Management Index (FMI) and/or swept area ratio (SAR) data. For both CPUE series 'nominal' assumes a 0% technology creep, for 'effective' a 2.6% technology creep is assumed. FMI uses FMI scores to develop a prior on recent fishing mortality rates, SAR does the same but based on swept area ratio. CMSY uses the methods from Froese et al. 2017 [@froese2017]. Guess assigns a random recent *F/F~MSY~* of 0.4,1, or 1.6. Panels ordered in descending (starting from top left) mean MAPE at the FAO region level",fig.width=8, fig.height=6}
ramu_mape_map_plot

ggsave(here("documents","figs","u-mape-map.pdf"),ram_mape_map_plot, width = 8, height = 6)

```

```{r uacc-map, fig.cap="Mean classification accuracy (assignment to general bin of overfishing, fishing near F~MSY~, and underfishing) by FAO statistical area arising from different data sources. RLSADB Index refers to catch and abundance index drawn from RLSADB. Effective CPUE refers to an index of abundance based on reconstructed effort data. Effective CPUE+ uses CPUE along with Fisheries Management Index (FMI) and/or swept area ratio (SAR) data. For both CPUE series 'nominal' assumes a 0% technology creep, for 'effective' a 2.6% technology creep is assumed. FMI uses FMI scores to develop a prior on recent fishing mortality rates, SAR does the same but based on swept area ratio. CMSY uses the methods from Froese et al. 2017 [@froese2017]. Guess assigns a random recent *F/F~MSY~* of 0.4,1, or 1.6. Panels ordered in descending (starting from top left) mean accuracy at the FAO region level",fig.width=8, fig.height=6}

ramu_acc_map_plot 

ggsave(here("documents","figs","u-acc-map.pdf"),ram_acc_map_plot, width = 8, height = 6)

```

