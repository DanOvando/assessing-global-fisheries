---
title: "Reviewer Replies"
author: "Dan Ovando"
date: "6/16/2021"
output: 
  bookdown::word_document2: default
bibliography: ["../references.bib"]
csl: fish-and-fisheries.csl
---

We thank both reviewers for their insightful and helpful comments. We have incorporated all of them into our revised manuscript unless otherwise stated, and we feel the suggestions have greatly improved the paper. 

We include specific replies to individual comments below. Our responses to comments are noted in *italics* following each comment. We have not included individual responses to all editorial comments (e.g. missing punctuation) but have resolved each of those instances pointed out by the reviewers. 

We hope the reviewers feel that our responses satisfy their concerns, but are happy to resolve any outstanding issues as required. 

# Reviewer 1


## Performance metrics


The stock status of a fish stock is commonly evaluated in terms of biomass and fishing mortality. The authors present all performance metrics for the regional fishery assessments (MPE, MAPE, and accuracy) only in terms of B/BMSY . For the case study, the authors present the stock status in terms of both B/BMSY and F/FMSY . Is there a reason why the authors considered only B/BMSY for the regional fishery assessments? I would be interested in all performance metrics in terms of F/FMSY and recommend to include this quantity for the regional fishery assessments at least for the supporting information.

*Good question. We focused on B/B~MSY~ as this project was originally designed with an eye towards improving the SOFIA status estimates, which consider B/B~MSY~, not F/F~MSY~. However, F/F~MSY~ is clearly of interest as well, particularly as catch-only model F/Fmsy outputs are often used for assessment or projection, in the manner of @costello2016a.*

*We added F/F~MSY~ performance metrics summarized in the same type of table and figures used in the main document to the Supporting Information (we do not include in the main text due to limitations on numbers of available figures and tables). We also briefly mention these results in the results and discussion section. Broadly, we find similar patterns of generally poor and variable performance, with the notable exception that while in terms of B/B~MSY~ the default settings of the version of CMSY used in this paper performed in the middle of the pack in most cases, in terms of F/F~MSY~ CMSY was last in terms of performance across every metric, due to severe positive biases in F/F~MSY~ .*

## Discussion of Results

Why did the authors not apply sraplus without any additional data (SAR, FMI) for the case studies? This would constitute a fairer comparison of the comparison of CMSY and sraplus.

*We have included the requested comparison in the case study section. Under these settings, which we call "Catch Heuristic", sraplus uses the same catch heuristics as CMSY to generate priors on terminal depletion. The only real difference between the two algorithms then is the presence of a prior on midpoint depletion in CMSY, and the use the prior-predictive tuning regime in sraplus. The prior-predictive tuning regime ensures that in the absence of new data to update the priors, the "posterior" more or less match the explicit priors on terminal depletion. This is why it produces two bands of stock status corresponding to the binary values proscribed by the catch-heuristic. CMSY "updates" those priors to produce the join prior-predictive distribution of the life history priors and explicit depletion priors conditional on the model and catch history.  We did not originally include this run in the case study set as our contention is not that the sraplus algorithm is an inherently better catch-only mousetrap than CMSY (though we feel the addition of the prior-predictive tuning procedure is an important option).But, we agree that inclusion of this run in the case studies highlights an important philosophical choice of the default settings of sraplus (that we should be explicit in where our prior in terminal depletion is coming from).*


The results reveal highly variable results and no consistent patterns among regions. Did the authors find any patterns in the assessment performance regarding the life-history parameters of the stocks? This aspect is currently lacking from the discussion.

*Good question. We have not explored this idea empirically, but we now mention it explicitly in the discussion as an area for future research.*

Similarly for the case studies, I wonder if the authors found any common characteristics for the stocks with larger biases?

*One reason that we identified and more clearly articulate in the results that the effort data wasn't helpful was that construction of a CPUE index based on fishery catches and large-scale estimated effort resulted in very low CPUE values during quota or market constrained periods in a fishery's history. During these periods, according to the CPUE index abundance was very low, but RLSADB reports relatively high biomass levels, causing the model to perform badly. We address this general idea of "why" of performance in the discussion now.*

Lastly, the conclusion that catch-only methods may be useful contradicts the findings of the case study and regional fishery assessments, which indicate a poor performance (high bias, low precision and low classification accuracy) of catch-only methods if no fishery-independent data or informative and unbiased depletion priors are available. If this is one of the main conclusions, the authors should elaborate in more detail what they imply with “when applied properly

*Both reviewers pointed this discrepancy out, and we agree. We have removed that statement, as well feel it contains too many nuances to be adequately covered in the concluding paragraph of the paper. The general point that there may be some uses for these methods is made in the discussion paragraph starting with "What quality of assessment..."*

## Specific Comments

*Thank you for the edits. All specific comments were accepted unless specifically noted below.*

l. 148pp. Why do you x the shape parameter rather than using the priors recommended by Thorson et al. (2012)?

*We believe the question here is why did we fix the shape parameter the mean values reported by @thorson2012, rather than taking those values as informative priors and estimating the shape parameter? We tried this, but it slowed the models down substantially, and often resulted in very poor fits / convergence given the lack of information in the data on this parameter. It also had a tendency to shoot the shape parameter into odd spaces, given the relatively large CVs around the values reported in @thorson2012. We have clarified this in the methods.*


l. 153 Please specify whether you follow Winker et al. (2018) defining BMSY/K = 0.25 (in your case) when BMSY/K < 0:25. If another assumptions is made, this needs to be specified.

*Good catch! In the results in the paper Bmsy / K is never below 0.25, though it comes close for Clupeiformes. However, you are correct that there was not a check for this possibility in the broader sraplus package, so we are adding that in in case users try and specify a shape parameter such that Bmsy/K < 0.25.*

*We have included the relevant table in the SI now.*


l. 169 Do you mean proc instead of obs? obs not defined at this point of the manuscript. Where is defined? It is mentioned in Table S1 as the ratio of process and observation error, but not mentioned in the main text. Consider lifting Table S1 to main text and add more explanation to on estimated parameters. Be specific whether proc is estimated or fixed. Are the priors of Table S2 used? Further, consider using Bo instead of B0 and define B0 as it can also be used as virgin biomass.

*Thank you for pointing these out. We have clarified the notation here and included expanded definitions in the text at the section in question. Unfortunately we do not have space to bring in another table to the main results, but we have stated explicitly how the default priors are used and pointed the readers to that table.*

Fig. 5 I am not sure that I understood the differences between the scenarios initial state known" and initial state unfished". Thus, I do not understand, why RMSE is higher for the scenario with the initial state unfished. Please provide more information about these scenarios.

*We have added the missing explanation of these states fo the Value of Information section of the methods.* 


Fig. 2-4 Keep same order of models/scenarios for all figures.

*After consultation with the group of authors, we respectfully disagree with this suggestion and as such have left the figures ordered as they are. The order of the panels reflects the performance of each data source by the metric in question, with best performing in the top left and worst in the bottom right. We feel this is helpful to the reader to parse apart the performance across the different data types. However, to clarify this we have made the caption clearer. However if you feel that this still introduces needless confusion we can make the figures in the manner suggested.*


Table S2 Where does the default prior of 1.01 for m come from? Thorson et al. (2012) report an average prior of 1.478 across all taxa.

*Good catch, that was an relic of an older set of results, we have updated the table to state that priors were drawn from @thorson2012, and provided a separate table with the specific values from @thorson2012 used.*

# Reviewer 2


General comments

Terms like biomass and notation B can often be used to refer to different things, ie., total biomass, vulnerable biomass, or spawning biomass. A non-structured model such as the SRA used here doesn’t distinguish between these three, and given the model is scaled with catches, B really represents vulnerable biomass; i.e., K = unfished vulnerable biomass, and the estimate of B/BMSY reported by the SRA corresponds with VB/VBMSY in a structured model. As the authors point out, the assessments in the RLSADB are typically more structurally complex – presumably many of them age-structured – and I assume report B/BMSY as SB/SBMSY given spawning population is generally the focus for conservation outcomes. The relationship between SB/SBMSY and VB/VBMSY would depend on the selectivity pattern relative to maturity and level of fishing mortality (eg VB/VBMSY could go to 0 while SB/SBMSY > 0). From a quick analysis with some operating models I have on hand the ratio of VB/VBMSY and SB/SBMSY ranged from 0.7 to 1.6.
If it is true that the SRA is reporting VB/VBMSY and comparing it to SB/SBMSY from the RLSADB there will be an additional level of bias and variability. This issue applies more widely any time outputs from models with fundamental structure are compared, but I rarely see it acknowledged or discussed. I don’t expect this would make a significant difference to the results of this study, and I don’t think this is a flaw in the study, but I’m curious if the authors have any thoughts on this.*

*We thank the reviewer for raising this important point. We have raised this issue broadly in the discussion section ("Our fits to the RLSADB data provide..."). We agree that this dynamic could explain the improved but still error-prone estimates of stock status when the model was fit with an index of abundance drawn directly from RLSADB. We have used this helpful suggestion to more clearly highlight the role that our results play in potentially quantifying the barrier that model misspecification plays in attempting to provide global assessments of age structured populations with surplus production models.*


It seems strange to me that having information on the most recent B/BMSY doesn’t result in lower RMSE for the predicted B/BMSY from the most recent 5 years of data (Figure 5). Presumably B/BMSY wouldn’t change a great deal between years, so it seems counter-intuitive that F/FMSY complete results in a better prediction of B/BMSY than when most recent B/BMSY is known. Perhaps the authors could add a bit of text to explain this.

*This is indeed confusing, as we did not clearly state that the value of information calculation measures performance based on B/B~MSY~ over the most recent five years of the fishery. We chose this as the metric as we noticed that catch-only models on occasion fit the last year of B/B~MSY~ well but do so by getting the prior years completely wrong. So, we chose a 5 year window to assess the ability of different data sources to get the most recent 5 years broadly right. This is why having 5 years of F/Fmsy is better, all else being equal, than 1 year of B/Bmsy (and 1 year of B/Bmsy is roughly equivalent to one year of F/Fmsy given the catch). We have clarified this in the value of information section of the Methods. We apologize for the confusion, and are happy to adjust the methods if the reviewer feels it is needed.*


The paragraph beginning on line 379 is useful, but from my perspective is a little overly generous to catch-only methods. The claim on this paper could be defended more strongly than is implied here. It’s logical that catch-only methods *need* some other data (or assumptions which are essentially assuming data look a certain way) to provide reliable estimate of stock status. E.g., even in unmanaged fisheries, the relationship between catch history and B/BMSY would have to at least depend on the time the stock has been fished, and the relative fishing effort on the stock (e.g., highly targeted, by-catch, etc). This paper makes the important point that providing estimates of stock status for unassessed fisheries requires better data (and capacity building to analyze the data); that is, essentially a stock assessment. Short-cut methods are appealing, but have the danger of over-simplifying a complex reality and could be detrimental to both sustainability and livelihoods if they don’t reliably categorize fisheries.

*Both reviewer's pointed out that some of the comments in our discussion did not seem to reflect the broadly poor performance of catch-only models shown in our results. We agree, and in the paragraph highlighted by the reviewer have sought to make clearer that any improvements have to come from new data, stronger assumptions, or improved empirical models. We then make clearer that this has largely been tried and we would argue largely failed. We have also included a paraphrased version of the reviewer's closing sentiments in the opening paragraph of our discussion.*

Minor comments

*We thank the reviewer for these comments. Unless otherwise stated all have been addressed*

56 – is it possible to say what % of the world’s fisheries this 50% of catch represents? 
*Not precisely, but it's a small percent, which we now clarify in the text. The FAO reports roughly 20000 individual "stocks", at least as defined by the intersection of taxa, country, and major FAO region. That resolution will be too coarse for some stocks (e.g. tuna) but likely too fine for others. The RLSADB contains roughly 1000 stocks at the moment, though fewer of those have consistent timeseries of reference points. So, an optimistic assessment would be 5% of fisheries?*

169 – what are sigma obs and gamma? Described later on I think.

*This was indeed unclear, we have clarified the definition of terms and added a table of prior distributions to the SI*

224 – has the SIR algorithm been described above? Hasn’t been mentioned yet – do you mean SRA?
*Our mistake, yes we mean SRA there*

305 – methods said Thorson 2012

*We have clarified that this refers to the intrinsic growth rate r, which comes from @thorson2020, as opposed to the shape parameter, which we pull from @thorson2012.*

306 – R2 values don’t match Figure 1? Fig 1 says R2 = 0.03 for CMSY

*To keep things more consistent with the rest of the paper we have replaced the R2 values in the plot with root mean squared error (RMSE) values, and double checked that the values in the text match the figures.*

313 – only SAR & FMI fit better to F/FMSY right? The others had higher R2 (though too low to consider) for B/BMSY (Figure 1)

*That is correct, much clearer now with RMSE instead of R2*

332 – did you consider sub-setting some of the RLSADB assessments to only use the earlier years where management may not have been as effective and B/BMSY in the terminal year less optimistic?

*This is a very interesting idea. We did consider this, the challenge is we only have FMI/SAR data for recent years, and so would not have been able to use those values to predict status in the past, when presumably both values would have been very different. We have another paper in the works where we have explored this exact idea though and found that catch-only models performed similarly poorly on RLSADB stocks even when restricted to pre-1990 data. We briefly mention this in the discussion now.*



441 – 449 – It may be worth pointing out that developing management methods that do not explicitly rely on an estimate of stock status could be useful as well, eg spatial closures, size regulations, empirical index-based MPs

*A very important point that we have included in the discussion in the suggested section.*

# References